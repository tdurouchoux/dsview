{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/review_links_small.csv\", newline='') as csv_file:\n",
    "\treader = csv.DictReader(csv_file)\n",
    "\tcontent_dict_list = [row_dict for row_dict in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Content extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dsview.content_loader import UrlLoader\n",
    "from dsview.content_extraction import ContentExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_extractor = ContentExtractor(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(content_dict_list[0][\"content_path\"])\n",
    "_, topics, _ = content_extractor.extract_content(content_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceSubject(type='AI Company', name='Microsoft', description='A leading technology company known for its software products and services.'),\n",
       " DataScienceSubject(type='Model', name='GraphRAG', description='A data pipeline and transformation suite designed to extract structured data from unstructured text using LLMs.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(content_dict_list[1][\"content_path\"])\n",
    "_, topics, _ = content_extractor.extract_content(content_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceSubject(type='Model', name='Claude 3.5 Sonnet', description='A model developed by Anthropic, known for its high performance across various context lengths.'),\n",
       " DataScienceSubject(type='Model', name='Gemini 1.5 Flash', description='A cost-effective model that balances performance and affordability, excelling in medium context tasks.'),\n",
       " DataScienceSubject(type='Model', name='Qwen2-72B-Instruct', description='An open-source model from Alibaba that performs well in short and medium context tasks.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(content_dict_list[2][\"content_path\"])\n",
    "_, topics, _ = content_extractor.extract_content(content_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceSubject(type='Organization', name='GitHub', description='A platform for software development and version control using Git.'),\n",
       " DataScienceSubject(type='Product', name='GitHub Models', description='A new feature enabling developers to leverage AI models for software development.'),\n",
       " DataScienceSubject(type='Product', name='GitHub Copilot', description='An AI-powered code completion tool that assists developers in writing code.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate subject llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from dsview.config import load_content_extraction_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_content_extraction_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ContentExtractionConfig' object has no attribute 'topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mDataScienceTopic\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mType of the described topic in the source.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43menum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mName of the described topic in the source.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m, in \u001b[0;36mDataScienceTopic\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataScienceTopic\u001b[39;00m(BaseModel):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mtype\u001b[39m: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(\n\u001b[1;32m      3\u001b[0m         default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType of the described topic in the source.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 5\u001b[0m         enum\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopics\u001b[49m,\n\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(\n\u001b[1;32m      8\u001b[0m         default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName of the described topic in the source.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     description: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(\n\u001b[1;32m     11\u001b[0m         default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m         description\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         ),\n\u001b[1;32m     18\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ContentExtractionConfig' object has no attribute 'topics'"
     ]
    }
   ],
   "source": [
    "class DataScienceTopic(BaseModel):\n",
    "    type: str = Field(\n",
    "        default=None,\n",
    "        description=\"Type of the described topic in the source.\",\n",
    "        enum=config.topics,\n",
    "    )\n",
    "    name: str = Field(\n",
    "        default=None, description=\"Name of the described topic in the source.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"General and detailed description of the topic, it should not \"\n",
    "            \"be a description of the source or how the source \"\n",
    "            \"tackle this topic. But the description must be \"\n",
    "            \"created using the provided or any prior knowledge.\"\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "class TopicsList(BaseModel):\n",
    "    topics: List[DataScienceTopic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\", \n",
    "\t\t\"\"\"You are an expert extraction algorithm specialized on Data Science related subjects.\n",
    "\t\tYour role is to extract relevant technical topics mentioned in a text.\n",
    "\t\tIf you do not know the value of an attribute asked to extract,\n",
    "\t\treturn null for the attribute's value.\"\"\"\n",
    "    ),\n",
    "\t\t(\"human\", \"Please extract informations from this source : {content}\"),\n",
    "\t]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_extractor = topic_prompt | llm.with_structured_output(schema=TopicsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = topic_extractor.invoke({\"content\": content_dict_list[0][\"content_path\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceTopic(type='AI Company', name='Microsoft', description='Microsoft is a multinational technology company known for its software products, including the Windows operating system and Microsoft Office suite, as well as hardware products and cloud services.'),\n",
       " DataScienceTopic(type='Model', name='GraphRAG', description='GraphRAG is a framework developed by Microsoft for integrating graph-based reasoning with retrieval-augmented generation (RAG) models, enabling enhanced performance in tasks that require both knowledge retrieval and generative capabilities.'),\n",
       " DataScienceTopic(type='Python library', name='PyTorch', description='PyTorch is an open-source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, and is known for its flexibility and ease of use.'),\n",
       " DataScienceTopic(type='Python library', name='Transformers', description='Transformers is a library developed by Hugging Face that provides pre-trained models and tools for natural language processing tasks, enabling users to easily implement state-of-the-art models.')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_list.topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics_list.topics[0].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics_list.topics[1].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(content_dict_list[0][\"content_path\"])\n",
    "_, topics, _ = content_extractor.extract_content(content_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceSubject(type='AI Company', name='Microsoft', description='Microsoft is a leading technology company known for its software products, cloud services, and AI research.'),\n",
       " DataScienceSubject(type='Model', name='GraphRAG', description='GraphRAG is a data pipeline and transformation suite designed to extract structured data from unstructured text using LLMs.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft is a leading technology company known for its software products, cloud services, and AI research.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.subjects[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GraphRAG is a data pipeline and transformation suite designed to extract structured data from unstructured text using LLMs.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.subjects[1].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics.subjects[0].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics.subjects[1].description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New content extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dsview.content_loader import UrlLoader\n",
    "from dsview.content_extraction import ContentExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_extractor = ContentExtractor(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(content_dict_list[0][\"content_path\"])\n",
    "_, content_description, topics, _ = content_extractor.extract_content(content_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContentDescription(title='GraphRAG: A Modular RAG System', content_type='Repository', tags=[DataScienceTag(name='Retrieval Augmented Generation')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceEntity(type='Organization', name='Microsoft', description='A multinational technology company known for its software products, including the Windows operating system and Microsoft Office suite.'),\n",
       " DataScienceEntity(type='Library', name='GraphRAG', description='A modular graph-based Retrieval-Augmented Generation (RAG) system designed to extract structured data from unstructured text using large language models (LLMs).')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(content_dict_list[1][\"content_path\"])\n",
    "_, content_description, topics, _ = content_extractor.extract_content(content_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContentDescription(title='LLM Hallucination Index RAG Special', content_type='Blog post', tags=[DataScienceTag(name='Large Language Model'), DataScienceTag(name='Retrieval Augmented Generation'), DataScienceTag(name='Model evaluation')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceEntity(type='AI Company', name='Anthropic', description='Anthropic is an AI safety and research company focused on developing advanced AI systems, including the Claude series of language models.'),\n",
       " DataScienceEntity(type='Model', name='claude-3-5-sonnet', description='Claude-3-5-Sonnet is a language model developed by Anthropic, known for its high performance in various context lengths.'),\n",
       " DataScienceEntity(type='Model', name='claude-3-opus', description='Claude-3-Opus is another variant of the Claude series by Anthropic, designed for improved performance in language tasks.'),\n",
       " DataScienceEntity(type='AI Company', name='Cohere', description='Cohere is an AI company that provides natural language processing models and tools, including the Command-R series.'),\n",
       " DataScienceEntity(type='Model', name='command-r-plus', description='Command-R Plus is a language model developed by Cohere, aimed at enhancing natural language understanding.'),\n",
       " DataScienceEntity(type='AI Company', name='Google', description='Google is a multinational technology company specializing in Internet-related services and products, including AI and machine learning.'),\n",
       " DataScienceEntity(type='Model', name='gemini-1.0-pro', description='Gemini-1.0-Pro is a language model developed by Google, part of the Gemini series.'),\n",
       " DataScienceEntity(type='Model', name='gemini-1.5-flash-001', description='Gemini-1.5-Flash-001 is a high-performance language model from Google, noted for its efficiency and cost-effectiveness.'),\n",
       " DataScienceEntity(type='Model', name='gemini-1.5-pro-001', description='Gemini-1.5-Pro-001 is an advanced version of the Gemini model series by Google.'),\n",
       " DataScienceEntity(type='AI Company', name='OpenAI', description='OpenAI is an AI research organization known for developing advanced AI models, including the GPT series.'),\n",
       " DataScienceEntity(type='Model', name='gpt-3.5-turbo-0125', description=\"GPT-3.5-Turbo-0125 is a variant of OpenAI's GPT-3.5 model, optimized for performance.\"),\n",
       " DataScienceEntity(type='Model', name='gpt-4o-2024-05-13', description='GPT-4o is an advanced language model from OpenAI, designed for high-level language understanding and generation.'),\n",
       " DataScienceEntity(type='AI Company', name='Mistral', description='Mistral is an AI company focused on developing open-source language models.'),\n",
       " DataScienceEntity(type='Model', name='mistral-large-2402', description='Mistral-Large-2402 is a large language model developed by Mistral, aimed at high-performance tasks.'),\n",
       " DataScienceEntity(type='Model', name='mistral-7b-instruct-v0.3', description=\"Mistral-7B-Instruct-v0.3 is a smaller variant of Mistral's models, designed for instruction-based tasks.\"),\n",
       " DataScienceEntity(type='Model', name='mixtral-8x22b-instruct-v0.1', description='Mixtral-8x22B-Instruct-v0.1 is a model from Mistral, focusing on instruction-based language tasks.'),\n",
       " DataScienceEntity(type='Model', name='mixtral-8x7b-instruct-v0.1', description='Mixtral-8x7B-Instruct-v0.1 is another variant from Mistral, designed for specific instruction tasks.'),\n",
       " DataScienceEntity(type='AI Company', name='Meta', description='Meta is a technology company known for its social media platforms and AI research, including the Llama series of models.'),\n",
       " DataScienceEntity(type='Model', name='meta-llama-3-70b-instruct', description='Meta-Llama-3-70B-Instruct is a large language model developed by Meta, optimized for instruction-based tasks.'),\n",
       " DataScienceEntity(type='Model', name='meta-llama-3-8b-instruct', description=\"Meta-Llama-3-8B-Instruct is a smaller variant of Meta's Llama models, designed for specific tasks.\"),\n",
       " DataScienceEntity(type='AI Company', name='Alibaba', description='Alibaba is a multinational conglomerate specializing in e-commerce, retail, and technology, including AI development.'),\n",
       " DataScienceEntity(type='Model', name='qwen2-1.5b-instruct', description='Qwen2-1.5B-Instruct is a language model developed by Alibaba, focusing on instruction-based tasks.'),\n",
       " DataScienceEntity(type='Model', name='qwen2-72b-instruct', description=\"Qwen2-72B-Instruct is a larger variant of Alibaba's Qwen series, designed for high-performance tasks.\"),\n",
       " DataScienceEntity(type='Model', name='qwen2-7b-instruct', description=\"Qwen2-7B-Instruct is a smaller model from Alibaba's Qwen series, aimed at specific instruction tasks.\"),\n",
       " DataScienceEntity(type='Model', name='qwen1.5-32b-chat', description='Qwen1.5-32B-Chat is a chat-focused model from Alibaba, designed for conversational tasks.'),\n",
       " DataScienceEntity(type='AI Company', name='Snowflake', description='Snowflake is a cloud-based data-warehousing company that also engages in AI and machine learning solutions.'),\n",
       " DataScienceEntity(type='Model', name='snowflake-arctic-instruct', description='Snowflake-Arctic-Instruct is a model developed by Snowflake, focusing on instruction-based tasks.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New subjects extraction tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from dsview.config import load_content_extraction_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_content_extraction_config()\n",
    "\n",
    "\n",
    "class DataScienceTopic(BaseModel):\n",
    "    type: str = Field(\n",
    "        default=None,\n",
    "        description=\"Type of the described topic in the source.\",\n",
    "        enum=config.components,\n",
    "    )\n",
    "    name: str = Field(\n",
    "        default=None, description=\"Name of the described topic in the source.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"General and detailed description of the topic, it should not \"\n",
    "            \"be a description of the source or how the source \"\n",
    "            \"tackle this topic. But the description must be \"\n",
    "            \"created using the provided information or any prior knowledge.\"\n",
    "        ),    \n",
    "    )\n",
    "    link: str = Field(\n",
    "\t\tdefault=None,\n",
    "\t\tdescription=\"If it exists, a link to a source explaining or introducing the topic\"\n",
    "\t)\n",
    "\n",
    "\n",
    "class TopicList(BaseModel):\n",
    "    entities: List[DataScienceTopic]\n",
    "\n",
    "entity_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\", \n",
    "\t\t\"\"\"You are part of an knowledge management system, you assist Data Scientists in their technical \n",
    "\t\treview process. The broader objective is to make it easier for a Data Scientist to track and \n",
    "\t\tunderstand new trends and tools. To this effect a network graphical interface will be created that \n",
    "\t\twill present knowledge and relations between sources.\n",
    "\n",
    "\t\tYou will be provided a text about a Data Science or related subject. Your role is to identify the main technical \n",
    "\t\ttopics that are introduced, explained or mentioned. The objective is to quickly highlight within a source,\n",
    "\t\twhat matter most and what could be used later by a Data Scientist. You should not extract details or specific\n",
    "\t\tinformation discussed in a text, the extracted topics must be as generic as possible or describe a specific practical tool. \n",
    "  \t\tIf the text is introducing a notion or a product, it must be included in the extracted topics. For example, \n",
    "\t\tif the text is extracted for a repository main page, the name of the library should be extracted.\n",
    "\n",
    "\t\tYou should ignore topics that are included in the following tags : {}.\n",
    "\n",
    "\t\tReduce the number of topics to a minimum. You must extract at most 5 topics that represents the most\n",
    "\t\tcrucial information within the text.  You may return less or none if \n",
    "\t\tnot enough information seems relevant.\n",
    "  \n",
    "    \t\"\"\".format(\", \".join(config.tags))\n",
    "    ),\n",
    "\t\t(\"human\", \"Please extract topics from this source : {content}\"),\n",
    "\t]\n",
    ")\n",
    "\n",
    "entity_extractor = entity_prompt | llm.with_structured_output(schema=TopicList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are an expert extraction algorithm specialized on Data Science related subjects.\n",
    "Your role is to extract technical entities discussed in a text, you must only extract the top 5 or less \n",
    "most relevant entities that reflect the essential points of the text. In this context, an entity \n",
    "is either an organization (governement entity, company, ...) or a technical tool / product (library, model, ...).\n",
    "You should not consider as entity the following informations : general technical concepts, technical architectures, model families, ... .\n",
    "You may return no entities if no information fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "introduced vs mentionned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsview.content_loader import UrlLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://github.com/pretzelai/pretzelai\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list = entity_extractor.invoke({\"content\": content_loader.content, \"links\": content_loader.links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceTopic(type='Library', name='PretzelAI', description=\"A modern, open-source alternative to Jupyter Notebooks that enhances Jupyter's capabilities with features like AI code generation, inline tab completion, and a sidebar for AI interaction.\", link='https://github.com/pretzelai/pretzelai'),\n",
       " DataScienceTopic(type='Platform', name='Pretzel', description='An improved version of Jupyter that allows for easy switching from Jupyter with support for existing configurations and extensions.', link='https://pretzelai.app'),\n",
       " DataScienceTopic(type='Concept', name='AI Code Generation', description='A feature that allows users to generate and edit code using AI, enhancing productivity and coding efficiency within the notebook environment.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Inline Tab Completion', description='A functionality that provides suggestions for code completion as the user types in a cell, improving coding speed and accuracy.', link=None),\n",
       " DataScienceTopic(type='Concept', name='AI Sidebar', description='A feature that enables users to interact with AI for code generation, error fixing, and querying within the notebook interface.', link=None)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_list.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://github.blog/news-insights/product-news/introducing-github-models/\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list = entity_extractor.invoke({\"content\": content_loader.content, \"links\": content_loader.links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceTopic(type='Library', name='GitHub Models', description='A platform enabling developers to leverage AI models for building applications directly within GitHub.', link=None),\n",
       " DataScienceTopic(type='Model', name='Llama 3.1', description=\"A language model that can be accessed and tested within GitHub's model playground.\", link=None),\n",
       " DataScienceTopic(type='Model', name='GPT-4o', description='An advanced language model suitable for building multimodal applications.', link=None),\n",
       " DataScienceTopic(type='Model', name='Mistral Large 2', description='A language model known for its low latency performance.', link=None),\n",
       " DataScienceTopic(type='Platform', name='Codespaces', description='A cloud-based development environment that allows developers to experiment with AI models and integrate them into their projects.', link=None)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_list.entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://github.com/microsoft/graphrag\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list = entity_extractor.invoke({\"content\": content_loader.content, \"links\": content_loader.links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceTopic(type='Library', name='GraphRAG', description='A modular graph-based Retrieval-Augmented Generation (RAG) system designed to enhance the reasoning capabilities of large language models (LLMs) by utilizing knowledge graph memory structures.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Retrieval-Augmented Generation (RAG)', description='A framework that combines retrieval of relevant information from a dataset with generative capabilities of language models to produce more accurate and contextually relevant outputs.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Knowledge Graph', description='A structured representation of information that captures relationships between entities, which can be used to enhance the performance of language models.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Prompt Tuning', description='A technique for optimizing the input prompts given to language models to improve their performance on specific tasks.', link=None),\n",
       " DataScienceTopic(type='Platform', name='Azure', description='A cloud computing platform by Microsoft that provides a range of services including those for deploying and managing applications and data.', link=None)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_list.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://www.rungalileo.io/hallucinationindex\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list = entity_extractor.invoke({\"content\": content_loader.content, \"links\": content_loader.links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceComponent(type='Concept', name='LLM Hallucination', description=\"The phenomenon where language models generate incorrect or nonsensical information, often referred to as 'hallucinations'. This is a critical area of study in evaluating the reliability of AI models.\", link=None),\n",
       " DataScienceComponent(type='Methodology', name='Retrieval-Augmented Generation (RAG)', description='A method that enhances the performance of language models by incorporating additional context from external sources, improving the accuracy and relevance of generated responses.', link=None),\n",
       " DataScienceComponent(type='Model', name='Claude 3.5 Sonnet', description='A language model developed by Anthropic, noted for its high performance across various context lengths and tasks, particularly in minimizing hallucinations.', link=None),\n",
       " DataScienceComponent(type='Model', name='Gemini 1.5 Flash', description='A cost-effective language model that balances performance and affordability, recognized for its strong performance in medium and long context tasks.', link=None),\n",
       " DataScienceComponent(type='Concept', name='Context Adherence', description='An evaluation metric used to measure how well a language model adheres to the provided context, assessing its factual accuracy and ability to avoid hallucinations.', link=None)]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_list.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://github.com/igrek51/wat\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list = entity_extractor.invoke({\"content\": content_loader.content, \"links\": content_loader.links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceTopic(type='Library', name='wat-inspector', description='A powerful inspection tool for Python that allows users to examine unknown objects at runtime, providing insights into their type, value, methods, and more.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Dynamic Typing', description='A feature of programming languages like Python where the type of a variable is determined at runtime, making it often challenging to ascertain the type of an object.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Object Inspection', description='The process of examining the properties and methods of an object in programming, which can aid in understanding and debugging code.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Python Interpreter', description='An environment where Python code is executed, allowing for interactive coding and debugging.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Code Debugging', description='The process of identifying and removing errors from computer code, often facilitated by tools that allow for inspection of variables and program flow.', link=None)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_list.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://docs.vllm.ai/en/latest/\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list = entity_extractor.invoke({\"content\": content_loader.content, \"links\": content_loader.links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataScienceTopic(type='Library', name='vLLM', description='vLLM is a fast and easy-to-use library for LLM inference and serving, optimized for high throughput and efficient memory management.', link=None),\n",
       " DataScienceTopic(type='Concept', name='PagedAttention', description='A memory management technique used in vLLM to efficiently handle attention key and value memory.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Quantization', description='A technique used in vLLM to reduce the model size and improve inference speed, supporting various formats like GPTQ, AWQ, INT4, INT8, and FP8.', link=None),\n",
       " DataScienceTopic(type='Concept', name='Continuous Batching', description='A method implemented in vLLM to enhance throughput in LLM inference by batching incoming requests continuously.', link=None),\n",
       " DataScienceTopic(type='Platform', name='OpenAI Compatible Server', description=\"A server setup in vLLM that is compatible with OpenAI's API, allowing for seamless integration and deployment.\", link=None)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_list.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = content_loader.content.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([word.startswith(\"http\") for word in content_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://openai.com/index/hello-gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_dsview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
