{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\", \n",
    "\t\t\"\"\"You are part of an knowledge management system, you assist Data Scientists in their technical \n",
    "\t\treview process. The broader objective is to make it easier for a Data Scientist to track and \n",
    "\t\tunderstand new trends and tools. \n",
    "\t\t\n",
    "\t\tYour role is to provide a  really concise summary of Data Science content. You must focus on the main\n",
    "  \t\ttechnical points and key takeaways. If the content is structured in chapters, you may mention them, but \n",
    "\t\tavoid doing a detailed description of each chapter.\n",
    "  \n",
    "\t\tThe output should not have a title.\n",
    "  \t\t\"\"\"\n",
    "    ),\n",
    "\t\t(\"user\", \"\"\" Please summarize the following content : {content}\n",
    "     \t\"\"\"),\n",
    "\t]\n",
    ")\n",
    "\n",
    "summary_generator = summary_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsview.content.content_loader import UrlLoader, Pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://towardsdatascience.com/automl-with-autogluon-transform-your-ml-workflow-with-just-four-lines-of-code-1d4b593be129\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary_generator.invoke({\"content\": content_loader.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon is an open-source AutoML framework designed to simplify the machine learning workflow. It allows users to achieve high-quality models with minimal coding effort, often requiring just four lines of code to set up and execute. Key features include:\n",
      "\n",
      "- **Ease of Use**: AutoGluon is user-friendly, making it accessible for both beginners and experienced data scientists.\n",
      "- **Model Selection and Tuning**: It automatically selects the best algorithms and tunes hyperparameters, optimizing model performance without manual intervention.\n",
      "- **Support for Various Data Types**: The framework can handle structured data, images, and text, making it versatile for different machine learning tasks.\n",
      "- **Ensemble Learning**: AutoGluon employs ensemble methods to combine multiple models, enhancing predictive accuracy.\n",
      "\n",
      "Overall, AutoGluon streamlines the machine learning process, enabling faster experimentation and deployment of models.\n"
     ]
    }
   ],
   "source": [
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content discusses AutoML (Automated Machine Learning) using AutoGluon, a library designed to simplify the machine learning workflow. Key points include:\n",
    "\n",
    "1. **Ease of Use**: AutoGluon allows users to build machine learning models with minimal code—often just four lines—making it accessible for both beginners and experienced practitioners.\n",
    "\n",
    "2. **Versatility**: The library supports various tasks, including classification, regression, and image classification, enabling users to apply it across different domains.\n",
    "\n",
    "3. **Model Selection and Ensembling**: AutoGluon automatically selects the best models and combines them to improve performance, streamlining the model development process.\n",
    "\n",
    "4. **Integration**: It integrates well with popular data science tools and frameworks, enhancing its usability within existing workflows.\n",
    "\n",
    "Overall, AutoGluon aims to accelerate the machine learning process by automating complex tasks, allowing data scientists to focus on higher-level problem-solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://readmedium.com/principal-components-analysis-pca-through-a-latent-variable-lens-2c2e5392a3a0\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary_generator.invoke({\"content\": content_loader.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilistic Principal Components Analysis (PPCA) is an extension of classical PCA that utilizes a latent variable framework to handle incomplete data through the EM algorithm. Unlike classical PCA, which is deterministic, PPCA incorporates a probabilistic model that separates signal from noise, allowing it to recover directions of maximal variance even when data is missing.\n",
      "\n",
      "Key points include:\n",
      "- PPCA assumes that noise follows an Isotropic Gaussian distribution and can be applied to data with missing values, a limitation of classical PCA.\n",
      "- The EM algorithm iteratively estimates latent variables and updates parameters, converging to maximum likelihood estimators.\n",
      "- The E-step computes expected values based on current estimates, while the M-step updates parameters like the loading matrix and mean vector.\n",
      "- Initial parameter values can be improved by mean imputation of missing data, enhancing convergence.\n",
      "- Simulations demonstrate that the EM algorithm for PPCA accurately estimates parameters even with missing data, showing robustness to non-random missingness patterns.\n",
      "\n",
      "Overall, PPCA provides a powerful alternative to classical PCA, particularly in scenarios involving incomplete datasets.\n"
     ]
    }
   ],
   "source": [
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Principal Components Analysis (PPCA) is an extension of classical PCA that utilizes a latent variable framework to handle incomplete data through the EM algorithm. Unlike classical PCA, which is deterministic, PPCA incorporates a probabilistic model that separates signal from noise, allowing it to recover directions of maximal variance even when data is missing.\n",
    "\n",
    "Key points include:\n",
    "- PPCA assumes that noise follows an Isotropic Gaussian distribution and can be applied to data with missing values, a limitation of classical PCA.\n",
    "- The EM algorithm iteratively estimates latent variables and updates parameters, converging to maximum likelihood estimators.\n",
    "- The E-step computes expected values based on current estimates, while the M-step updates parameters like the loading matrix and mean vector.\n",
    "- Initial parameter values can be improved by mean imputation of missing data, enhancing convergence.\n",
    "- Simulations demonstrate that the EM algorithm for PPCA accurately estimates parameters even with missing data, showing robustness to non-random missingness patterns.\n",
    "\n",
    "Overall, PPCA provides a powerful alternative to classical PCA, particularly in scenarios involving incomplete datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Principal Components Analysis (PPCA) is an extension of classical PCA that utilizes a latent variable framework to effectively handle incomplete data through the Expectation-Maximization (EM) algorithm. Unlike classical PCA, which is deterministic and does not separate signal from noise, PPCA incorporates a probabilistic model that assumes the presence of latent variables and noise following an Isotropic Gaussian distribution.\n",
    "\n",
    "Key points include:\n",
    "\n",
    "1. **Relationship to Classical PCA**: PPCA can recover directions of maximal variance similar to classical PCA, but it also accommodates missing data, which classical PCA cannot handle. The probabilistic components may differ in scaling and orientation but span the same subspace.\n",
    "\n",
    "2. **EM Algorithm**: The EM algorithm iteratively estimates latent variables and updates parameters. The E-step computes expected values based on current estimates, while the M-step maximizes the expected log-likelihood. This process continues until convergence.\n",
    "\n",
    "3. **Handling Missing Data**: The EM algorithm for PPCA is adapted to manage missing values by initializing parameters with mean imputation and iteratively updating estimates for the loading matrix, mean vector, and noise variance.\n",
    "\n",
    "4. **Implementation and Simulations**: The article provides a Python implementation of the EM algorithm for PPCA, testing it under various conditions, including complete data and different patterns of missingness. Results indicate that the algorithm performs well, maintaining accuracy even with non-random missing data.\n",
    "\n",
    "5. **Conclusion**: PPCA extends the capabilities of classical PCA by effectively managing incomplete datasets, demonstrating robustness in parameter estimation across different missing data scenarios.\n",
    "\n",
    "Overall, PPCA is a powerful tool for dimensionality reduction, particularly in situations where data completeness cannot be guaranteed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loader = UrlLoader(\"https://github.com/microsoft/graphrag\")\n",
    "content_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary_generator.invoke({\"content\": content_loader.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary of GitHub - microsoft/graphrag: A Modular Graph-Based Retrieval-Augmented Generation (RAG) System**\n",
      "\n",
      "GraphRAG is a project developed by Microsoft that focuses on enhancing the capabilities of large language models (LLMs) by utilizing a modular graph-based approach for Retrieval-Augmented Generation (RAG). The system is designed to extract structured data from unstructured text, improving the reasoning abilities of LLMs with private data.\n",
      "\n",
      "**Key Features:**\n",
      "- **Data Pipeline and Transformation Suite:** GraphRAG provides tools to transform unstructured text into meaningful structured data.\n",
      "- **Knowledge Graph Memory Structures:** It employs knowledge graphs to enhance the outputs of LLMs.\n",
      "- **User-Friendly Experience:** The GraphRAG Solution Accelerator offers an end-to-end experience using Azure resources.\n",
      "- **Prompt Tuning:** Users are encouraged to fine-tune prompts for optimal results, guided by a dedicated Prompt Tuning Guide.\n",
      "\n",
      "**Considerations:**\n",
      "- **Cost of Indexing:** Users should be aware that indexing can be expensive and should start with small datasets.\n",
      "- **Evaluation Metrics:** The project includes metrics for evaluating performance and understanding limitations.\n",
      "\n",
      "**Documentation and Community Engagement:**\n",
      "- The repository includes comprehensive documentation, contribution guidelines, and a platform for community discussions.\n",
      "\n",
      "**Licensing:** The project is licensed under the MIT license.\n",
      "\n",
      "For more information, users can refer to the official documentation and the Microsoft Research Blog.\n"
     ]
    }
   ],
   "source": [
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of GitHub - microsoft/graphrag: A Modular Graph-Based Retrieval-Augmented Generation (RAG) System**\n",
    "\n",
    "GraphRAG is a project developed by Microsoft that focuses on enhancing the capabilities of large language models (LLMs) by utilizing a modular graph-based approach for Retrieval-Augmented Generation (RAG). The system is designed to extract structured data from unstructured text, improving the reasoning abilities of LLMs with private data.\n",
    "\n",
    "**Key Features:**\n",
    "- **Data Pipeline and Transformation Suite:** GraphRAG provides tools to transform unstructured text into meaningful structured data.\n",
    "- **Knowledge Graph Memory Structures:** It employs knowledge graphs to enhance the outputs of LLMs.\n",
    "- **User-Friendly Experience:** The GraphRAG Solution Accelerator offers an end-to-end experience using Azure resources.\n",
    "- **Prompt Tuning:** Users are encouraged to fine-tune prompts for optimal results, guided by a dedicated Prompt Tuning Guide.\n",
    "\n",
    "**Considerations:**\n",
    "- **Cost of Indexing:** Users should be aware that indexing can be expensive and should start with small datasets.\n",
    "- **Evaluation Metrics:** The project includes metrics for evaluating performance and understanding limitations.\n",
    "\n",
    "**Documentation and Community Engagement:**\n",
    "- The repository includes comprehensive documentation, contribution guidelines, and a platform for community discussions.\n",
    "\n",
    "**Licensing:** The project is licensed under the MIT license.\n",
    "\n",
    "For more information, users can refer to the official documentation and the Microsoft Research Blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsview.extraction.content_extraction import get_summary_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_summary_generator = get_summary_generator(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = old_summary_generator.invoke({\"content\": content_loader.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary of GitHub - microsoft/graphrag: A Modular Graph-Based Retrieval-Augmented Generation (RAG) System**\n",
      "\n",
      "**Theme and Context:**\n",
      "The GraphRAG project is an open-source initiative by Microsoft that focuses on enhancing the capabilities of Large Language Models (LLMs) through a modular graph-based Retrieval-Augmented Generation (RAG) system. It aims to extract structured data from unstructured text, thereby improving the reasoning abilities of LLMs when dealing with private data.\n",
      "\n",
      "**Key Concepts:**\n",
      "- **Retrieval-Augmented Generation (RAG):** A method that combines retrieval of relevant information with generative capabilities of LLMs to produce more accurate and contextually relevant outputs.\n",
      "- **Knowledge Graphs:** The project utilizes knowledge graph memory structures to enhance the outputs of LLMs, allowing for better organization and retrieval of information.\n",
      "- **Data Pipeline and Transformation:** GraphRAG serves as a suite for transforming unstructured text into meaningful, structured data, facilitating better data management and utilization.\n",
      "\n",
      "**Takeaways:**\n",
      "- **User-Friendly Experience:** The GraphRAG system offers a Solution Accelerator package for an easy start, particularly with Azure resources.\n",
      "- **Prompt Tuning:** Users are encouraged to fine-tune their prompts for optimal results, as out-of-the-box performance may not meet expectations.\n",
      "- **Cost Considerations:** Indexing with GraphRAG can be resource-intensive, and users are advised to understand the associated costs and start with smaller datasets.\n",
      "- **Community Engagement:** The project encourages community feedback and contributions through GitHub Discussions, fostering collaboration and improvement.\n",
      "\n",
      "Overall, GraphRAG represents a significant step in leveraging LLMs for more effective data processing and retrieval, with a focus on responsible AI practices.\n"
     ]
    }
   ],
   "source": [
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of GitHub - microsoft/graphrag: A Modular Graph-Based Retrieval-Augmented Generation (RAG) System**\n",
    "\n",
    "**Theme and Context:**\n",
    "The GraphRAG project is an open-source initiative by Microsoft that focuses on enhancing the capabilities of Large Language Models (LLMs) through a modular graph-based Retrieval-Augmented Generation (RAG) system. It aims to extract structured data from unstructured text, thereby improving the reasoning abilities of LLMs when dealing with private data.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Retrieval-Augmented Generation (RAG):** A method that combines retrieval of relevant information with generative capabilities of LLMs to produce more accurate and contextually relevant outputs.\n",
    "- **Knowledge Graphs:** The project utilizes knowledge graph memory structures to enhance the outputs of LLMs, allowing for better organization and retrieval of information.\n",
    "- **Data Pipeline and Transformation:** GraphRAG serves as a suite for transforming unstructured text into meaningful, structured data, facilitating better data management and utilization.\n",
    "\n",
    "**Takeaways:**\n",
    "- **User-Friendly Experience:** The GraphRAG system offers a Solution Accelerator package for an easy start, particularly with Azure resources.\n",
    "- **Prompt Tuning:** Users are encouraged to fine-tune their prompts for optimal results, as out-of-the-box performance may not meet expectations.\n",
    "- **Cost Considerations:** Indexing with GraphRAG can be resource-intensive, and users are advised to understand the associated costs and start with smaller datasets.\n",
    "- **Community Engagement:** The project encourages community feedback and contributions through GitHub Discussions, fostering collaboration and improvement.\n",
    "\n",
    "Overall, GraphRAG represents a significant step in leveraging LLMs for more effective data processing and retrieval, with a focus on responsible AI practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_dsview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
